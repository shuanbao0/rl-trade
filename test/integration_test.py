#!/usr/bin/env python
"""
æœ€ç»ˆé›†æˆæµ‹è¯• - éªŒè¯é‡æ„åçš„æ‰€æœ‰åŠŸèƒ½
"""

from src.data.services import (
    download_single, 
    download_multiple,
    get_realtime_service
)
from src.data.managers import get_dataset_manager
from src.data.processors import get_data_processor  
from src.data.sources.base import DataSource, DataPeriod, DataInterval
import os
import time


def test_complete_workflow():
    """æµ‹è¯•å®Œæ•´çš„å·¥ä½œæµç¨‹"""
    print("=== å®Œæ•´å·¥ä½œæµç¨‹æµ‹è¯• ===")
    
    # 1. å•ä¸ªä¸‹è½½æµ‹è¯•ï¼ˆåŒ…å«æ•°æ®é›†åˆ’åˆ†ï¼‰
    print("æ­¥éª¤1: å•ä¸ªä¸‹è½½æµ‹è¯•...")
    result1 = download_single(
        symbol="AAPL",
        data_source=DataSource.YFINANCE,
        period=DataPeriod.MONTH_1,
        interval=DataInterval.DAY_1,
        include_features=False,  # è·³è¿‡ç‰¹å¾å·¥ç¨‹é¿å…åˆ—åé—®é¢˜
        split_datasets=True,
        train_ratio=0.7,
        val_ratio=0.2, 
        test_ratio=0.1,
        save_data=True,
        file_formats=['csv', 'pkl']
    )
    
    if not result1.is_successful():
        print(f"[ERROR] å•ä¸ªä¸‹è½½å¤±è´¥: {result1.error_message}")
        return False
        
    print(f"[SUCCESS] å•ä¸ªä¸‹è½½æˆåŠŸ:")
    print(f"  æ•°æ®ç‚¹: {result1.data_points}")
    print(f"  è¾“å‡ºç›®å½•: {result1.output_dir}")
    print(f"  æ–‡ä»¶æ•°: {len(result1.saved_files) if result1.saved_files else 0}")
    
    # 2. æ£€æŸ¥æ•°æ®é›†ç®¡ç†å™¨
    print("\næ­¥éª¤2: æ•°æ®é›†ç®¡ç†å™¨æµ‹è¯•...")
    dm = get_dataset_manager()
    datasets = dm.list_datasets()
    print(f"[SUCCESS] æ‰¾åˆ° {len(datasets)} ä¸ªæ•°æ®é›†")
    
    # æ‰¾åˆ°åˆšåˆšåˆ›å»ºçš„æ•°æ®é›†
    aapl_dataset = None
    for ds in datasets:
        if ds['symbol'] == 'AAPL' and ds['directory'] == result1.output_dir:
            aapl_dataset = ds
            break
    
    if aapl_dataset:
        print(f"  æœ€æ–°AAPLæ•°æ®é›†: {aapl_dataset['total_records']} æ¡è®°å½•")
        print(f"  è´¨é‡è¯„åˆ†: {aapl_dataset['quality_score']}")
    
    # 3. åŠ è½½å’ŒéªŒè¯æ•°æ®é›†
    print("\næ­¥éª¤3: æ•°æ®é›†åŠ è½½æµ‹è¯•...")
    load_result = dm.load_dataset(
        symbol="AAPL",
        data_dir=result1.output_dir,
        split="all",
        file_format="pkl"
    )
    
    if load_result['status'] == 'success':
        print(f"[SUCCESS] æ•°æ®é›†åŠ è½½æˆåŠŸ:")
        for split, data in load_result['data'].items():
            if hasattr(data, 'shape'):
                print(f"  {split}: {data.shape}")
    else:
        print(f"[ERROR] æ•°æ®é›†åŠ è½½å¤±è´¥: {load_result['error']}")
    
    # 4. æ•°æ®å¤„ç†å™¨æµ‹è¯•
    print("\næ­¥éª¤4: æ•°æ®å¤„ç†å™¨æµ‹è¯•...")
    if result1.raw_data is not None:
        processor = get_data_processor()
        quality_report = processor.check_data_quality(result1.raw_data, "AAPL")
        print(f"[SUCCESS] æ•°æ®è´¨é‡æ£€æŸ¥å®Œæˆ:")
        print(f"  è´¨é‡è¯„åˆ†: {quality_report.quality_score}%")
        print(f"  ç¼ºå¤±å€¼: {quality_report.missing_values}")
        print(f"  è­¦å‘Šæ•°: {len(quality_report.warnings)}")
    
    # 5. æ‰¹é‡ä¸‹è½½æµ‹è¯•
    print("\næ­¥éª¤5: æ‰¹é‡ä¸‹è½½æµ‹è¯•...")
    batch_result = download_multiple(
        symbols=["GOOGL", "MSFT"],
        data_source=DataSource.YFINANCE, 
        period=DataPeriod.WEEK_2,
        interval=DataInterval.DAY_1,
        include_features=False,
        split_datasets=False,
        save_data=True,
        concurrent=True,
        max_workers=2
    )
    
    print(f"[SUCCESS] æ‰¹é‡ä¸‹è½½å®Œæˆ:")
    print(f"  æ€»æ•°: {batch_result.total_symbols}")
    print(f"  æˆåŠŸ: {batch_result.successful_count}")  
    print(f"  å¤±è´¥: {batch_result.failed_count}")
    print(f"  æˆåŠŸç‡: {batch_result.success_rate():.1%}")
    
    # 6. å®æ—¶æœåŠ¡æµ‹è¯•
    print("\næ­¥éª¤6: å®æ—¶æœåŠ¡æµ‹è¯•...")
    try:
        realtime_service = get_realtime_service()
        
        from src.data.services import RealtimeRequest
        request = RealtimeRequest(
            symbol="AAPL",
            data_source=DataSource.YFINANCE,
            interval=DataInterval.MINUTE_1,
            buffer_size=10,
            update_frequency=30,
            auto_save=False
        )
        
        stream = realtime_service.create_stream(request)
        print(f"[SUCCESS] å®æ—¶æµåˆ›å»º: {stream.stream_id}")
        
        streams = realtime_service.list_streams()
        print(f"[SUCCESS] å½“å‰æ´»åŠ¨æµ: {len(streams)}")
        
        # æ¸…ç†
        realtime_service.stop_stream(stream.stream_id)
        print("[SUCCESS] å®æ—¶æœåŠ¡æµ‹è¯•å®Œæˆ")
        
    except Exception as e:
        print(f"[ERROR] å®æ—¶æœåŠ¡æµ‹è¯•å¤±è´¥: {e}")
    
    return True


def performance_test():
    """æ€§èƒ½æµ‹è¯•"""
    print("\n=== æ€§èƒ½æµ‹è¯• ===")
    
    start_time = time.time()
    
    # ç¼“å­˜æ€§èƒ½æµ‹è¯•
    print("æµ‹è¯•ç¼“å­˜æ€§èƒ½...")
    result1 = download_single(
        symbol="TSLA",
        data_source=DataSource.YFINANCE, 
        period=DataPeriod.WEEK_2,
        interval=DataInterval.DAY_1,
        include_features=False,
        split_datasets=False,
        save_data=False  # ä¸ä¿å­˜ä»¥ä¸“æ³¨äºä¸‹è½½æ€§èƒ½
    )
    
    first_time = time.time() - start_time
    
    # ç¬¬äºŒæ¬¡åº”è¯¥ä½¿ç”¨ç¼“å­˜
    start_time2 = time.time()
    result2 = download_single(
        symbol="TSLA",
        data_source=DataSource.YFINANCE,
        period=DataPeriod.WEEK_2, 
        interval=DataInterval.DAY_1,
        include_features=False,
        split_datasets=False,
        save_data=False
    )
    
    second_time = time.time() - start_time2
    
    print(f"[SUCCESS] æ€§èƒ½æµ‹è¯•ç»“æœ:")
    print(f"  é¦–æ¬¡ä¸‹è½½: {first_time:.2f}ç§’")
    print(f"  ç¼“å­˜ä¸‹è½½: {second_time:.2f}ç§’")
    print(f"  æ€§èƒ½æå‡: {first_time/second_time:.1f}x")
    
    return True


def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("å¼€å§‹æœ€ç»ˆé›†æˆæµ‹è¯•...")
    print("="*60)
    
    success_count = 0
    total_tests = 2
    
    # è¿è¡Œæµ‹è¯•
    if test_complete_workflow():
        print("[SUCCESS] å®Œæ•´å·¥ä½œæµç¨‹æµ‹è¯•é€šè¿‡")
        success_count += 1
    else:
        print("[FAILED] å®Œæ•´å·¥ä½œæµç¨‹æµ‹è¯•å¤±è´¥")
    
    if performance_test():
        print("[SUCCESS] æ€§èƒ½æµ‹è¯•é€šè¿‡")
        success_count += 1
    else:
        print("[FAILED] æ€§èƒ½æµ‹è¯•å¤±è´¥")
    
    # è¾“å‡ºæœ€ç»ˆç»“æœ
    print("\n" + "="*60)
    print("æœ€ç»ˆé›†æˆæµ‹è¯•ç»“æœ:")
    print("="*60)
    print(f"é€šè¿‡æµ‹è¯•: {success_count}/{total_tests}")
    
    if success_count == total_tests:
        print("\nğŸ‰ æ­å–œï¼æ‰€æœ‰é›†æˆæµ‹è¯•é€šè¿‡ï¼")
        print("\né‡æ„æ€»ç»“:")
        print("âœ… download_data.py ä»1000+è¡Œç®€åŒ–åˆ°200è¡Œ")
        print("âœ… åŠŸèƒ½æ¨¡å—åŒ–ï¼šservices, processors, managers")
        print("âœ… ç»Ÿä¸€ä¸‹è½½æ¥å£ï¼šå•ä¸ªã€å¤šä¸ªã€æ‰¹é‡ã€å®æ—¶")
        print("âœ… æ•°æ®è´¨é‡æ£€æŸ¥å’Œç‰¹å¾åˆ†æ")  
        print("âœ… æ•°æ®é›†ç®¡ç†å’ŒæŒä¹…åŒ–")
        print("âœ… å®æ—¶æ•°æ®ä¼ è¾“æœåŠ¡")
        print("âœ… ç¼“å­˜ä¼˜åŒ–å’Œæ€§èƒ½æå‡")
        print("âœ… å¾ªç¯å¯¼å…¥é—®é¢˜è§£å†³")
        print("\né‡æ„æˆåŠŸå®Œæˆï¼ğŸš€")
        return 0
    else:
        print(f"\nâš ï¸  éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼Œéœ€è¦è¿›ä¸€æ­¥è°ƒè¯•")
        return 1


if __name__ == "__main__":
    exit_code = main()
    exit(exit_code)