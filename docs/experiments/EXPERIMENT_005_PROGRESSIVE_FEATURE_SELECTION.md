# Experiment #005: æ¸è¿›å¼ç‰¹å¾é€‰æ‹©ä¸ç§‘å­¦éªŒè¯

## å®éªŒæ¦‚è¿°

**å®éªŒç¼–å·**: #005  
**å®éªŒåç§°**: åŸºäºç§‘å­¦æ–¹æ³•è®ºçš„æ¸è¿›å¼ç‰¹å¾é€‰æ‹©å®éªŒ  
**å®éªŒæ—¥æœŸ**: 2025å¹´8æœˆ12æ—¥ - è®¡åˆ’å¼€å§‹  
**å®éªŒç›®æ ‡**: è§£å†³#004æš´éœ²çš„æ ¸å¿ƒé—®é¢˜ï¼Œå»ºç«‹ç§‘å­¦çš„ç‰¹å¾å·¥ç¨‹æ–¹æ³•è®º  
**å®éªŒçŠ¶æ€**: âš ï¸ Phase 1 å·²å®Œæˆï¼Œå‘ç°å…³é”®é—®é¢˜  
**å®é™…æ—¶é•¿**: Phase 1: 1.5å°æ—¶è®­ç»ƒ + åˆ†æ

---

## å®éªŒèƒŒæ™¯ä¸é—®é¢˜è¯†åˆ«

### Experiment #004æš´éœ²çš„æ ¸å¿ƒé—®é¢˜

#### 1. ç»´åº¦ç¾éš¾é—®é¢˜ ğŸ¯
```
é—®é¢˜è¡¨ç°:
- ç‰¹å¾æ•°é‡: 3 â†’ 117 (39å€è·³è·ƒ)
- æ€§èƒ½ç»“æœ: é¢„æœŸ+50~170% â†’ å®é™…-43.69%
- æ ¹æœ¬åŸå› : é«˜ç»´ç‰¹å¾ç©ºé—´å¯¼è‡´å­¦ä¹ å›°éš¾

ç†è®ºæ”¯æ’‘:
- åœ¨é«˜ç»´ç©ºé—´ä¸­ï¼Œæ•°æ®å˜å¾—ç¨€ç–
- æ ·æœ¬é—´è·ç¦»è¶‹äºç›¸ç­‰ï¼Œæ¨¡å¼è¯†åˆ«å›°éš¾
- RLç®—æ³•çš„æ¢ç´¢æ•ˆç‡æ˜¾è‘—ä¸‹é™
```

#### 2. å¥–åŠ±å‡½æ•°å¤±é…é—®é¢˜ ğŸ’°
```
é—®é¢˜è¡¨ç°:
- å¥–åŠ±å€¼: +94542.43 (å¼‚å¸¸é«˜)
- å›æŠ¥ç‡: -43.69% (æå·®)
- ä¸ä¸€è‡´æ€§: ä¸¥é‡çš„ä¿¡å·å¤±çœŸ

æ ¹æœ¬åŸå› :
- å¥–åŠ±å‡½æ•°ä¸å®é™…äº¤æ˜“ç›®æ ‡è„±èŠ‚
- å¯èƒ½å­˜åœ¨æ•°å€¼ç¨³å®šæ€§é—®é¢˜
- åœ¨é«˜ç»´ç©ºé—´ä¸­äº§ç”Ÿè¯¯å¯¼ä¿¡å·
```

#### 3. ç‰¹å¾è´¨é‡é—®é¢˜ ğŸ“Š
```
é—®é¢˜è¯†åˆ«:
- å†—ä½™ç‰¹å¾: å¤šä¸ªé«˜åº¦ç›¸å…³çš„æŒ‡æ ‡
- å™ªå£°ç‰¹å¾: ç»Ÿè®¡ä¸ç¨³å®šçš„å¤æ‚æŒ‡æ ‡
- æ—¶é—´å¯¹é½: å¤šæ—¶é—´æ¡†æ¶ç‰¹å¾çš„åŒæ­¥é—®é¢˜
```

#### 4. è®­ç»ƒä¸å……åˆ†é—®é¢˜ â°
```
è®­ç»ƒé…ç½®é—®é¢˜:
- å½“å‰è®­ç»ƒ: 3M timesteps
- ç†è®ºéœ€æ±‚: 117 Ã— 50k = 5.85M timesteps
- è®­ç»ƒä¸è¶³: 95%çš„æ—¶é—´ç¼ºå£
```

#### 5. å¤–æ±‡å¸‚åœºé€‚åº”æ€§é—®é¢˜ ğŸŒ
```
å¸‚åœºå·®å¼‚:
- AAPL (è‚¡ç¥¨): -14.33% å›æŠ¥
- EURUSD (å¤–æ±‡): -90% åˆ° -43.69%
- é—®é¢˜: ç¼ºä¹å¤–æ±‡å¸‚åœºä¸“é—¨åŒ–é…ç½®
```

---

## å®éªŒè®¾è®¡ç†å¿µ

### ç§‘å­¦æ–¹æ³•è®ºåŸåˆ™

#### 1. æ¸è¿›å¼éªŒè¯ ğŸ”¬
```python
# ç§‘å­¦çš„ç‰¹å¾æ·»åŠ æµç¨‹
é˜¶æ®µå¼éªŒè¯åŸåˆ™:
Phase 1: 3ä¸ªæ ¸å¿ƒç‰¹å¾ â†’ å»ºç«‹åŸºå‡†æ€§èƒ½
Phase 2: +2-3ä¸ªç‰¹å¾ â†’ éªŒè¯æ¯ä¸ªç‰¹å¾çš„å¢å€¼
Phase 3: +2-3ä¸ªç‰¹å¾ â†’ æŒç»­éªŒè¯å’Œä¼˜åŒ–
æ¯é˜¶æ®µè¦æ±‚: æ˜¾è‘—æ€§èƒ½æå‡æ‰ç»§ç»­ä¸‹ä¸€é˜¶æ®µ
```

#### 2. æ§åˆ¶å˜é‡åŸåˆ™ âš—ï¸
```python
# ä¸¥æ ¼çš„å®éªŒæ§åˆ¶
å›ºå®šå˜é‡:
- ç®—æ³•: PPO
- æ•°æ®é›†: ç›¸åŒçš„EURUSDæ•°æ®
- è®­ç»ƒæ—¶é—´: æ¯é˜¶æ®µå›ºå®štimesteps
- ç¡¬ä»¶ç¯å¢ƒ: ç›¸åŒçš„è®¡ç®—èµ„æº

å˜åŒ–å˜é‡:
- ç‰¹å¾æ•°é‡: é€æ­¥å¢åŠ 
- ç‰¹å¾ç±»å‹: ç§‘å­¦é€‰æ‹©
```

#### 3. ç»Ÿè®¡æ˜¾è‘—æ€§æ£€éªŒ ğŸ“ˆ
```python
# ä¸¥æ ¼çš„æ€§èƒ½éªŒè¯
æ˜¾è‘—æ€§æ£€éªŒè¦æ±‚:
- å¤šæ¬¡é‡å¤å®éªŒ (3-5æ¬¡)
- ç»Ÿè®¡æ˜¾è‘—æ€§æ£€éªŒ (p < 0.05)
- ç½®ä¿¡åŒºé—´è®¡ç®—
- æ•ˆæœå¤§å°è¯„ä¼°
```

---

## è¯¦ç»†å®éªŒè®¾è®¡

### Phase 1: åŸºå‡†å»ºç«‹ (ç¬¬1å‘¨)

#### ç›®æ ‡
å»ºç«‹ç¨³å®šå¯é çš„3ç‰¹å¾åŸºå‡†æ€§èƒ½

#### Phase 1A: å¥–åŠ±å‡½æ•°é‡æ„ ğŸ”§
```python
# æ–°è®¾è®¡çš„ç›´æ¥å›æŠ¥å¥–åŠ±å‡½æ•°
class DirectReturnReward(BaseReward):
    """
    è§£å†³#004å¥–åŠ±-å›æŠ¥ä¸ä¸€è‡´é—®é¢˜çš„æ–°å¥–åŠ±å‡½æ•°
    """
    
    def __init__(self, config):
        super().__init__(config)
        self.risk_penalty = config.risk_penalty  # 0.1
        self.transaction_cost = config.transaction_cost  # 0.0001
        
    def calculate_reward(self, observation, action, next_observation):
        # è®¡ç®—å®é™…å›æŠ¥ç‡
        price_change = (next_observation['close'] - observation['close']) / observation['close']
        
        # åŸºäºå®é™…æŒä»“çš„å›æŠ¥
        position = self.get_position_from_action(action)
        raw_return = position * price_change
        
        # æ‰£é™¤äº¤æ˜“æˆæœ¬
        transaction_cost = abs(action - self.prev_action) * self.transaction_cost
        
        # é£é™©è°ƒæ•´
        volatility = self.calculate_volatility(observation)
        risk_adjusted_return = raw_return - (volatility * self.risk_penalty)
        
        # æœ€ç»ˆå¥–åŠ± = å®é™…å›æŠ¥ - æˆæœ¬ - é£é™©æƒ©ç½š
        reward = risk_adjusted_return - transaction_cost
        
        return reward * 100  # æ”¾å¤§åˆ°åˆç†æ•°å€¼èŒƒå›´
```

#### Phase 1B: åŸºå‡†ç‰¹å¾é€‰æ‹© ğŸ“Š
```python
# ç²¾é€‰çš„3ä¸ªæ ¸å¿ƒç‰¹å¾ï¼ˆåŸºäºé‡‘èç†è®ºï¼‰
PHASE1_FEATURES = {
    'trend': 'EMA_21',      # è¶‹åŠ¿è·Ÿè¸ªï¼š21æ—¥æŒ‡æ•°ç§»åŠ¨å¹³å‡
    'momentum': 'RSI_14',   # åŠ¨é‡æŒ‡æ ‡ï¼š14æ—¥ç›¸å¯¹å¼ºå¼±æŒ‡æ•°
    'volatility': 'ATR_14'  # æ³¢åŠ¨ç‡ï¼š14æ—¥å¹³å‡çœŸå®æ³¢å¹…
}

# é€‰æ‹©ä¾æ®ï¼š
# 1. EMA_21: æ¯”SMAæ›´æ•æ„Ÿï¼Œ21æ˜¯æ–æ³¢é‚£å¥‘æ•°
# 2. RSI_14: ç»å…¸åŠ¨é‡æŒ‡æ ‡ï¼Œ14æ—¥æ˜¯æ ‡å‡†å‘¨æœŸ
# 3. ATR_14: ä»£æ›¿MACDï¼Œæä¾›çº¯ç²¹çš„æ³¢åŠ¨ç‡ä¿¡æ¯
```

#### Phase 1C: ä¸¥æ ¼åŸºå‡†æµ‹è¯•
```python
# åŸºå‡†æµ‹è¯•é…ç½®
BASELINE_CONFIG = {
    'algorithm': 'PPO',
    'total_timesteps': 1_000_000,  # 1Mæ­¥ï¼Œç¡®ä¿æ”¶æ•›
    'learning_rate': 3e-4,
    'reward_function': 'direct_return',
    'features': PHASE1_FEATURES,
    'episodes_for_evaluation': 20,  # æ›´å¤šepisodeè·å¾—ç¨³å®šç»Ÿè®¡
    'repetitions': 5  # 5æ¬¡é‡å¤å®éªŒ
}
```

#### Phase 1D: æˆåŠŸæ ‡å‡†
```python
# Phase 1æˆåŠŸæ ‡å‡†
PHASE1_SUCCESS_CRITERIA = {
    'mean_return': > -20%,    # æ˜¾è‘—æ”¹å–„å½“å‰-43.69%
    'win_rate': > 20%,        # ä»0%æå‡åˆ°20%+
    'sharpe_ratio': > -1.0,   # ä»-4368æ”¹å–„åˆ°åˆç†æ°´å¹³
    'reward_consistency': reward/returnç›¸å…³ç³»æ•° > 0.8
}
```

### Phase 2: åŠ¨é‡å¢å¼º (ç¬¬1-2å‘¨)

#### ç›®æ ‡
åœ¨ç¨³å®šåŸºå‡†åŸºç¡€ä¸Šï¼Œç§‘å­¦æ·»åŠ åŠ¨é‡ç±»ç‰¹å¾

#### Phase 2A: åŠ¨é‡ç‰¹å¾å€™é€‰ ğŸ“ˆ
```python
# åŸºäºé‡‘èç†è®ºçš„åŠ¨é‡ç‰¹å¾å€™é€‰
MOMENTUM_CANDIDATES = {
    'williams_r': {
        'indicator': 'Williams %R',
        'period': 14,
        'theory': 'å¨å»‰æ–¯%Rï¼Œè¡¡é‡ä¹°å–å‹åŠ›',
        'expected_benefit': 'è¯†åˆ«è¶…ä¹°è¶…å–çŠ¶æ€'
    },
    'cci': {
        'indicator': 'Commodity Channel Index',
        'period': 20,
        'theory': 'CCIæŒ‡æ ‡ï¼Œè¡¡é‡ä»·æ ¼åç¦»ç¨‹åº¦',
        'expected_benefit': 'è¯†åˆ«è¶‹åŠ¿åè½¬ç‚¹'
    },
    'stochastic_k': {
        'indicator': 'Stochastic %K',
        'period': 14,
        'theory': 'éšæœºæŒ‡æ ‡ï¼Œä»·æ ¼åœ¨åŒºé—´ä¸­çš„ä½ç½®',
        'expected_benefit': 'çŸ­æœŸä¹°å–ä¿¡å·'
    }
}
```

#### Phase 2B: å•ç‰¹å¾éªŒè¯
```python
# æ¯ä¸ªå€™é€‰ç‰¹å¾çš„å•ç‹¬éªŒè¯
for feature_name, feature_config in MOMENTUM_CANDIDATES.items():
    # é…ç½®ï¼šåŸºå‡†3ç‰¹å¾ + å½“å‰å€™é€‰ç‰¹å¾
    test_features = PHASE1_FEATURES.copy()
    test_features[f'momentum_2_{feature_name}'] = feature_config['indicator']
    
    # è®­ç»ƒå’Œè¯„ä¼°
    result = train_and_evaluate(test_features, PHASE1_CONFIG)
    
    # ç»Ÿè®¡æ˜¾è‘—æ€§æ£€éªŒ
    improvement = statistical_test(result, phase1_baseline)
    
    # è®°å½•ç»“æœ
    if improvement.significant and improvement.effect_size > 0.2:
        approved_features.append(feature_name)
```

#### Phase 2C: æœ€ä½³ç‰¹å¾é€‰æ‹©
```python
# åŸºäºéªŒè¯ç»“æœé€‰æ‹©æœ€ä½³åŠ¨é‡ç‰¹å¾
PHASE2_FEATURES = PHASE1_FEATURES.copy()
PHASE2_FEATURES.update(select_best_features(approved_features, max_count=2))

# é¢„æœŸé…ç½®ç¤ºä¾‹
PHASE2_EXPECTED = {
    'trend': 'EMA_21',
    'momentum_1': 'RSI_14',
    'momentum_2': 'Williams_R_14',  # å‡è®¾éªŒè¯æœ€ä½³
    'volatility': 'ATR_14',
    'momentum_3': 'CCI_20'          # å‡è®¾éªŒè¯æ¬¡ä½³
}
```

### Phase 3: æ³¢åŠ¨ç‡å¢å¼º (ç¬¬2å‘¨)

#### Phase 3A: æ³¢åŠ¨ç‡ç‰¹å¾å€™é€‰
```python
VOLATILITY_CANDIDATES = {
    'bb_width': {
        'indicator': 'Bollinger Bands Width',
        'period': 20,
        'theory': 'å¸ƒæ—å¸¦å®½åº¦ï¼Œè¡¡é‡ä»·æ ¼æ³¢åŠ¨èŒƒå›´',
        'expected_benefit': 'è¯†åˆ«æ³¢åŠ¨ç‡å˜åŒ–'
    },
    'historical_volatility': {
        'indicator': 'Historical Volatility',
        'period': 20,
        'theory': 'å†å²æ³¢åŠ¨ç‡ï¼ŒåŸºäºæ”¶ç›Šç‡æ ‡å‡†å·®',
        'expected_benefit': 'é£é™©åº¦é‡å’Œä½ç½®è°ƒæ•´'
    },
    'atr_ratio': {
        'indicator': 'ATR Ratio',
        'calculation': 'ATR_14 / ATR_50',
        'theory': 'ATRæ¯”ç‡ï¼ŒçŸ­æœŸvsé•¿æœŸæ³¢åŠ¨ç‡',
        'expected_benefit': 'æ³¢åŠ¨ç‡è¶‹åŠ¿è¯†åˆ«'
    }
}
```

### Phase 4: è¶‹åŠ¿å¼ºåŒ– (ç¬¬2-3å‘¨)

#### Phase 4A: è¶‹åŠ¿ç‰¹å¾å€™é€‰
```python
TREND_CANDIDATES = {
    'adx': {
        'indicator': 'Average Directional Index',
        'period': 14,
        'theory': 'ADXæŒ‡æ ‡ï¼Œè¡¡é‡è¶‹åŠ¿å¼ºåº¦',
        'expected_benefit': 'è¯†åˆ«å¼ºè¶‹åŠ¿vsç›˜æ•´'
    },
    'ema_slope': {
        'indicator': 'EMA Slope',
        'calculation': '(EMA_21_today - EMA_21_5days_ago) / 5',
        'theory': 'EMAæ–œç‡ï¼Œè¶‹åŠ¿æ–¹å‘å’Œå¼ºåº¦',
        'expected_benefit': 'é‡åŒ–è¶‹åŠ¿å˜åŒ–'
    },
    'price_channel': {
        'indicator': 'Price Channel Position',
        'period': 20,
        'theory': 'ä»·æ ¼åœ¨é«˜ä½é€šé“ä¸­çš„ä½ç½®',
        'expected_benefit': 'æ”¯æ’‘é˜»åŠ›ä½åˆ¤æ–­'
    }
}
```

### Phase 5: æœ€ç»ˆä¼˜åŒ– (ç¬¬3å‘¨)

#### Phase 5A: ç‰¹å¾é‡è¦æ€§åˆ†æ
```python
# ä½¿ç”¨SHAPæˆ–ç‰¹å¾é‡è¦æ€§åˆ†æ
from sklearn.inspection import permutation_importance

def analyze_feature_importance(model, X, y):
    """åˆ†ææ¯ä¸ªç‰¹å¾å¯¹æ¨¡å‹æ€§èƒ½çš„è´¡çŒ®"""
    
    # è®¡ç®—æ’åˆ—é‡è¦æ€§
    perm_importance = permutation_importance(model, X, y, 
                                           scoring='neg_mean_squared_error',
                                           n_repeats=10)
    
    # ç”Ÿæˆé‡è¦æ€§æŠ¥å‘Š
    importance_report = pd.DataFrame({
        'feature': X.columns,
        'importance': perm_importance.importances_mean,
        'std': perm_importance.importances_std
    }).sort_values('importance', ascending=False)
    
    return importance_report
```

#### Phase 5B: ç‰¹å¾å‰ªæ
```python
def prune_features(features, importance_report, threshold=0.01):
    """ç§»é™¤é‡è¦æ€§ä½äºé˜ˆå€¼çš„ç‰¹å¾"""
    
    low_importance = importance_report[
        importance_report['importance'] < threshold
    ]['feature'].tolist()
    
    pruned_features = {k: v for k, v in features.items() 
                      if k not in low_importance}
    
    return pruned_features
```

---

## è§£å†³æ–¹æ¡ˆè®¾è®¡

### 1. å¥–åŠ±å‡½æ•°é‡æ„ ğŸ’°

#### å½“å‰é—®é¢˜
```python
# #004ä¸­çš„é—®é¢˜
å¹³å‡å¥–åŠ±: +94542.43
å¹³å‡å›æŠ¥: -43.69%
ç›¸å…³ç³»æ•°: æ¥è¿‘0 (å®Œå…¨ä¸ç›¸å…³)
```

#### æ–°è®¾è®¡è§£å†³æ–¹æ¡ˆ
```python
class OptimizedForexReward(BaseReward):
    """
    ä¸“ä¸ºå¤–æ±‡äº¤æ˜“ä¼˜åŒ–çš„æ–°å¥–åŠ±å‡½æ•°
    è§£å†³#004ä¸­å¥–åŠ±-å›æŠ¥ä¸ä¸€è‡´é—®é¢˜
    """
    
    def __init__(self, config):
        super().__init__(config)
        # å…³é”®å‚æ•°é…ç½®
        self.return_weight = 1.0        # å›æŠ¥æƒé‡
        self.risk_penalty = 0.1         # é£é™©æƒ©ç½š
        self.transaction_cost = 0.0001  # äº¤æ˜“æˆæœ¬
        self.consistency_bonus = 0.05   # ä¸€è‡´æ€§å¥–åŠ±
        
    def calculate_reward(self, prev_portfolio, current_portfolio, action):
        # 1. è®¡ç®—å®é™…å›æŠ¥ç‡
        actual_return = (current_portfolio - prev_portfolio) / prev_portfolio
        
        # 2. è®¡ç®—äº¤æ˜“æˆæœ¬
        position_change = abs(action - self.prev_action)
        cost = position_change * self.transaction_cost
        
        # 3. è®¡ç®—é£é™©æƒ©ç½šï¼ˆåŸºäºæ³¢åŠ¨ç‡ï¼‰
        volatility = self.estimate_volatility()
        risk_penalty = volatility * self.risk_penalty * abs(action)
        
        # 4. åŸºç¡€å¥–åŠ± = å®é™…å›æŠ¥
        base_reward = actual_return * self.return_weight
        
        # 5. æœ€ç»ˆå¥–åŠ±
        final_reward = base_reward - cost - risk_penalty
        
        # 6. æ•°å€¼èŒƒå›´æ§åˆ¶ï¼ˆé¿å…å¼‚å¸¸å¤§çš„æ•°å€¼ï¼‰
        final_reward = np.clip(final_reward, -1.0, 1.0)
        
        return final_reward
        
    def validate_consistency(self, rewards, returns):
        """éªŒè¯å¥–åŠ±ä¸å›æŠ¥çš„ä¸€è‡´æ€§"""
        correlation = np.corrcoef(rewards, returns)[0, 1]
        return correlation > 0.8  # è¦æ±‚å¼ºæ­£ç›¸å…³
```

### 2. è®­ç»ƒæ—¶é—´ç§‘å­¦è®¡ç®— â°

#### åŠ¨æ€è®­ç»ƒæ—¶é—´åˆ†é…
```python
def calculate_required_timesteps(num_features, base_timesteps=500_000):
    """
    åŸºäºç‰¹å¾æ•°é‡ç§‘å­¦è®¡ç®—æ‰€éœ€è®­ç»ƒæ—¶é—´
    """
    # åŸºäºç»éªŒå…¬å¼ï¼šæ¯ä¸ªç‰¹å¾éœ€è¦50k-100kæ­¥
    feature_factor = num_features * 75_000
    
    # å¤æ‚åº¦å› å­ï¼ˆéçº¿æ€§å¢é•¿ï¼‰
    complexity_factor = 1 + (num_features - 3) * 0.1
    
    # æœ€ç»ˆè®­ç»ƒæ—¶é—´
    required_timesteps = int(base_timesteps + feature_factor * complexity_factor)
    
    return required_timesteps

# å„é˜¶æ®µè®­ç»ƒæ—¶é—´åˆ†é…
TRAINING_SCHEDULE = {
    'phase_1': calculate_required_timesteps(3),    # ~725k steps
    'phase_2': calculate_required_timesteps(5),    # ~1.075M steps
    'phase_3': calculate_required_timesteps(7),    # ~1.425M steps
    'phase_4': calculate_required_timesteps(9),    # ~1.775M steps
}
```

### 3. å¤–æ±‡å¸‚åœºä¸“ä¸šåŒ–é…ç½® ğŸŒ

#### å¤–æ±‡ç‰¹æœ‰çš„é…ç½®ä¼˜åŒ–
```python
FOREX_SPECIALIZED_CONFIG = {
    # å¤–æ±‡å¸‚åœºç‰¹å¾
    'market_hours': '24/5',  # 24å°æ—¶5å¤©äº¤æ˜“
    'high_liquidity': True,
    'low_transaction_costs': True,
    'high_leverage': True,
    
    # ä¸“ç”¨å‚æ•°è°ƒæ•´
    'learning_rate': 1e-4,    # æ›´å°çš„å­¦ä¹ ç‡é€‚åº”å¤–æ±‡æ³¢åŠ¨
    'batch_size': 128,        # æ›´å¤§æ‰¹æ¬¡å¤„ç†é«˜é¢‘æ•°æ®
    'n_steps': 4096,          # æ›´å¤šæ­¥æ•°æ”¶é›†ç»éªŒ
    
    # å¤–æ±‡ä¸“ç”¨ç‰¹å¾é…ç½®
    'feature_config': {
        'price_precision': 5,      # å¤–æ±‡5ä½å°æ•°ç²¾åº¦
        'volatility_window': 14,   # é€‚åˆå¤–æ±‡çš„æ³¢åŠ¨ç‡çª—å£
        'trend_sensitivity': 0.8,  # å¤–æ±‡è¶‹åŠ¿æ•æ„Ÿåº¦
    },
    
    # é£é™©ç®¡ç†å‚æ•°
    'max_position': 0.95,      # æœ€å¤§ä»“ä½é™åˆ¶
    'stop_loss': 0.02,         # 2%æ­¢æŸ
    'take_profit': 0.04,       # 4%æ­¢ç›ˆ
}
```

### 4. ç‰¹å¾é€‰æ‹©ç§‘å­¦åŒ–æ¡†æ¶ ğŸ”¬

#### ç‰¹å¾è¯„ä¼°çŸ©é˜µ
```python
class FeatureEvaluator:
    """ç§‘å­¦çš„ç‰¹å¾è¯„ä¼°å’Œé€‰æ‹©æ¡†æ¶"""
    
    def __init__(self):
        self.evaluation_metrics = [
            'performance_improvement',  # æ€§èƒ½æ”¹è¿›
            'statistical_significance', # ç»Ÿè®¡æ˜¾è‘—æ€§
            'feature_importance',       # ç‰¹å¾é‡è¦æ€§
            'correlation_redundancy',   # ç›¸å…³æ€§å†—ä½™
            'computational_cost',       # è®¡ç®—æˆæœ¬
            'financial_theory_support'  # é‡‘èç†è®ºæ”¯æŒ
        ]
    
    def evaluate_feature(self, feature_name, baseline_performance, 
                        new_performance, feature_data):
        """å…¨é¢è¯„ä¼°å•ä¸ªç‰¹å¾çš„ä»·å€¼"""
        
        scores = {}
        
        # 1. æ€§èƒ½æ”¹è¿›è¯„åˆ†
        perf_improvement = (new_performance['return'] - baseline_performance['return']) / abs(baseline_performance['return'])
        scores['performance'] = min(max(perf_improvement, -1), 1)
        
        # 2. ç»Ÿè®¡æ˜¾è‘—æ€§è¯„åˆ†
        p_value = self.statistical_test(baseline_performance, new_performance)
        scores['significance'] = 1 - p_value if p_value < 0.05 else 0
        
        # 3. ç‰¹å¾é‡è¦æ€§è¯„åˆ†
        importance = self.calculate_feature_importance(feature_data)
        scores['importance'] = importance
        
        # 4. å†—ä½™åº¦è¯„åˆ†ï¼ˆä¸ç°æœ‰ç‰¹å¾çš„ç›¸å…³æ€§ï¼‰
        redundancy = self.calculate_redundancy(feature_data)
        scores['redundancy'] = 1 - redundancy  # è¶Šä¸å†—ä½™åˆ†æ•°è¶Šé«˜
        
        # 5. è®¡ç®—æˆæœ¬è¯„åˆ†
        cost = self.estimate_computational_cost(feature_name)
        scores['cost'] = 1 - cost  # æˆæœ¬è¶Šä½åˆ†æ•°è¶Šé«˜
        
        # 6. ç†è®ºæ”¯æŒè¯„åˆ†
        theory_score = self.assess_financial_theory_support(feature_name)
        scores['theory'] = theory_score
        
        # ç»¼åˆè¯„åˆ†ï¼ˆåŠ æƒå¹³å‡ï¼‰
        weights = {
            'performance': 0.3,
            'significance': 0.2,
            'importance': 0.2,
            'redundancy': 0.1,
            'cost': 0.1,
            'theory': 0.1
        }
        
        final_score = sum(scores[k] * weights[k] for k in weights)
        
        return {
            'overall_score': final_score,
            'individual_scores': scores,
            'recommendation': self.make_recommendation(final_score)
        }
    
    def make_recommendation(self, score):
        """åŸºäºè¯„åˆ†ç»™å‡ºç‰¹å¾ä½¿ç”¨å»ºè®®"""
        if score >= 0.7:
            return "ACCEPT - å¼ºçƒˆæ¨èä½¿ç”¨"
        elif score >= 0.5:
            return "CONDITIONAL - è°¨æ…ä½¿ç”¨ï¼Œéœ€è¦è¿›ä¸€æ­¥éªŒè¯"
        else:
            return "REJECT - ä¸æ¨èä½¿ç”¨"
```

---

## å®éªŒç›‘æ§å’Œè´¨é‡æ§åˆ¶

### 1. å®æ—¶ç›‘æ§ç³»ç»Ÿ

#### å…³é”®æŒ‡æ ‡ç›‘æ§
```python
MONITORING_METRICS = {
    'performance_metrics': [
        'mean_return',
        'sharpe_ratio', 
        'max_drawdown',
        'win_rate'
    ],
    'training_metrics': [
        'loss_convergence',
        'reward_stability',
        'gradient_norm',
        'learning_rate_adaptation'
    ],
    'consistency_metrics': [
        'reward_return_correlation',
        'episode_variance',
        'action_distribution',
        'feature_utilization'
    ]
}
```

#### å¼‚å¸¸æ£€æµ‹ç³»ç»Ÿ
```python
class ExperimentAnomalyDetector:
    """å®éªŒè¿‡ç¨‹å¼‚å¸¸æ£€æµ‹ç³»ç»Ÿ"""
    
    def __init__(self):
        self.thresholds = {
            'reward_explosion': 1000,      # å¥–åŠ±å€¼å¼‚å¸¸æ£€æµ‹
            'loss_divergence': 10,         # æŸå¤±å‘æ•£æ£€æµ‹
            'performance_drop': -0.5,      # æ€§èƒ½éª¤é™æ£€æµ‹
            'correlation_break': 0.3       # ç›¸å…³æ€§ç ´åæ£€æµ‹
        }
    
    def detect_anomalies(self, training_metrics):
        anomalies = []
        
        # æ£€æµ‹å¥–åŠ±å€¼å¼‚å¸¸
        if abs(training_metrics['mean_reward']) > self.thresholds['reward_explosion']:
            anomalies.append({
                'type': 'reward_explosion',
                'severity': 'high',
                'action': 'stop_training'
            })
        
        # æ£€æµ‹æŸå¤±å‘æ•£
        if training_metrics['loss_trend'] > self.thresholds['loss_divergence']:
            anomalies.append({
                'type': 'loss_divergence',
                'severity': 'medium',
                'action': 'adjust_learning_rate'
            })
        
        return anomalies
```

### 2. è´¨é‡ä¿è¯æœºåˆ¶

#### å¤šæ¬¡é‡å¤éªŒè¯
```python
def conduct_rigorous_experiment(phase_config, num_repetitions=5):
    """è¿›è¡Œä¸¥æ ¼çš„å¤šæ¬¡é‡å¤å®éªŒ"""
    
    results = []
    
    for i in range(num_repetitions):
        # è®¾ç½®ä¸åŒçš„éšæœºç§å­
        set_random_seed(42 + i)
        
        # è®­ç»ƒæ¨¡å‹
        model, training_metrics = train_model(phase_config)
        
        # è¯„ä¼°æ¨¡å‹
        eval_results = evaluate_model(model, num_episodes=20)
        
        results.append({
            'repetition': i + 1,
            'training_metrics': training_metrics,
            'evaluation_results': eval_results
        })
    
    # ç»Ÿè®¡åˆ†æ
    statistical_summary = analyze_results_statistics(results)
    
    return results, statistical_summary
```

#### ç»Ÿè®¡æ˜¾è‘—æ€§æ£€éªŒ
```python
def statistical_significance_test(baseline_results, new_results, alpha=0.05):
    """ç»Ÿè®¡æ˜¾è‘—æ€§æ£€éªŒ"""
    from scipy import stats
    
    baseline_returns = [r['mean_return'] for r in baseline_results]
    new_returns = [r['mean_return'] for r in new_results]
    
    # Welch's t-test (é€‚ç”¨äºä¸ç­‰æ–¹å·®)
    t_stat, p_value = stats.ttest_ind(new_returns, baseline_returns, 
                                     equal_var=False)
    
    # æ•ˆæœå¤§å° (Cohen's d)
    pooled_std = np.sqrt((np.var(baseline_returns) + np.var(new_returns)) / 2)
    cohens_d = (np.mean(new_returns) - np.mean(baseline_returns)) / pooled_std
    
    result = {
        'p_value': p_value,
        'significant': p_value < alpha,
        't_statistic': t_stat,
        'effect_size': cohens_d,
        'effect_interpretation': interpret_effect_size(cohens_d)
    }
    
    return result

def interpret_effect_size(d):
    """è§£é‡Šæ•ˆæœå¤§å°"""
    abs_d = abs(d)
    if abs_d < 0.2:
        return "å°æ•ˆåº”"
    elif abs_d < 0.5:
        return "ä¸­ç­‰æ•ˆåº”"
    elif abs_d < 0.8:
        return "å¤§æ•ˆåº”"
    else:
        return "éå¸¸å¤§æ•ˆåº”"
```

---

## æˆåŠŸæ ‡å‡†ä¸è¯„ä¼°ä½“ç³»

### å„é˜¶æ®µæˆåŠŸæ ‡å‡†

#### Phase 1: åŸºå‡†å»ºç«‹æˆåŠŸæ ‡å‡†
```python
PHASE1_SUCCESS = {
    'primary_metrics': {
        'mean_return': {
            'target': "> -20%",
            'current_baseline': -43.69,
            'improvement_required': "23.69%ç»å¯¹æ”¹å–„"
        },
        'reward_return_correlation': {
            'target': "> 0.8",
            'current_baseline': "æ¥è¿‘0",
            'improvement_required': "å¼ºæ­£ç›¸å…³å»ºç«‹"
        }
    },
    'secondary_metrics': {
        'win_rate': "> 20%",
        'sharpe_ratio': "> -1.0",
        'max_drawdown': "< 50%",
        'training_stability': "æŸå¤±æ”¶æ•›ä¸”ç¨³å®š"
    }
}
```

#### Phase 2-4: æ¸è¿›æ”¹è¿›æ ‡å‡†
```python
PROGRESSIVE_IMPROVEMENT = {
    'minimum_improvement': {
        'performance': "æ¯é˜¶æ®µè‡³å°‘5%å›æŠ¥æ”¹å–„",
        'significance': "p < 0.05ç»Ÿè®¡æ˜¾è‘—",
        'effect_size': "Cohen's d > 0.2"
    },
    'cumulative_targets': {
        'phase_2': "å¹³å‡å›æŠ¥ > -15%",
        'phase_3': "å¹³å‡å›æŠ¥ > -10%", 
        'phase_4': "å¹³å‡å›æŠ¥ > -5%",
        'final_target': "å¹³å‡å›æŠ¥ > 0% (ç›ˆåˆ©)"
    }
}
```

### å®éªŒç»ˆæ­¢æ¡ä»¶

#### æ—©æœŸæˆåŠŸç»ˆæ­¢
```python
EARLY_SUCCESS_CONDITIONS = {
    'exceptional_performance': {
        'mean_return': "> 10%",
        'sharpe_ratio': "> 1.0",
        'win_rate': "> 60%"
    },
    'action': "åœ¨å½“å‰é˜¶æ®µåœæ­¢ï¼Œè¿›è¡Œæ·±åº¦åˆ†æå’Œä¼˜åŒ–"
}
```

#### æ—©æœŸå¤±è´¥ç»ˆæ­¢
```python
EARLY_FAILURE_CONDITIONS = {
    'severe_degradation': {
        'mean_return': "< -60%",  # æ¯”#004æ›´å·®
        'training_instability': "è¿ç»­å‘æ•£æˆ–å¼‚å¸¸",
        'correlation_failure': "ç›¸å…³ç³»æ•° < 0.3"
    },
    'action': "åœæ­¢å®éªŒï¼Œé‡æ–°å®¡è§†æ–¹æ³•è®º"
}
```

---

## é£é™©ç¼“è§£ç­–ç•¥

### 1. è®¡ç®—èµ„æºç®¡ç†
```python
RESOURCE_MANAGEMENT = {
    'training_time_limits': {
        'phase_1': "æœ€å¤§12å°æ—¶",
        'phase_2': "æœ€å¤§24å°æ—¶",
        'phase_3': "æœ€å¤§36å°æ—¶",
        'phase_4': "æœ€å¤§48å°æ—¶"
    },
    'memory_optimization': {
        'batch_processing': "åˆ†æ‰¹å¤„ç†å¤§å‹æ•°æ®é›†",
        'feature_caching': "æ™ºèƒ½ç¼“å­˜è®¡ç®—ç»“æœ",
        'garbage_collection': "ä¸»åŠ¨å†…å­˜ç®¡ç†"
    }
}
```

### 2. å®éªŒå›æ»šæœºåˆ¶
```python
class ExperimentCheckpoint:
    """å®éªŒæ£€æŸ¥ç‚¹å’Œå›æ»šæœºåˆ¶"""
    
    def __init__(self):
        self.checkpoints = {}
    
    def save_checkpoint(self, phase_name, model, results, config):
        """ä¿å­˜å®éªŒæ£€æŸ¥ç‚¹"""
        self.checkpoints[phase_name] = {
            'model': model,
            'results': results,
            'config': config,
            'timestamp': datetime.now()
        }
    
    def rollback_to_phase(self, phase_name):
        """å›æ»šåˆ°æŒ‡å®šé˜¶æ®µ"""
        if phase_name in self.checkpoints:
            return self.checkpoints[phase_name]
        else:
            raise ValueError(f"Checkpoint {phase_name} not found")
```

### 3. é¢„æœŸé£é™©ä¸åº”å¯¹

#### é«˜æ¦‚ç‡é£é™©
```python
EXPECTED_RISKS = {
    'overfitting_risk': {
        'probability': 'high',
        'impact': 'medium',
        'mitigation': [
            'ä¸¥æ ¼çš„æ ·æœ¬å¤–éªŒè¯',
            'æ­£åˆ™åŒ–æŠ€æœ¯åº”ç”¨',
            'æ—©åœæœºåˆ¶å®æ–½'
        ]
    },
    'feature_correlation': {
        'probability': 'medium',
        'impact': 'medium', 
        'mitigation': [
            'ç›¸å…³æ€§åˆ†æ',
            'VIFè†¨èƒ€å› å­æ£€æŸ¥',
            'ä¸»æˆåˆ†åˆ†æè€ƒè™‘'
        ]
    }
}
```

---

## é¢„æœŸç»“æœä¸å½±å“

### ä¿å®ˆé¢„æœŸ
```python
CONSERVATIVE_EXPECTATIONS = {
    'phase_1': {
        'mean_return': "ä»-43.69%æ”¹å–„åˆ°-25%",
        'correlation_fix': "å»ºç«‹å¥–åŠ±-å›æŠ¥æ­£ç›¸å…³",
        'stability': "è®­ç»ƒè¿‡ç¨‹ç¨³å®šæ”¶æ•›"
    },
    'final_outcome': {
        'mean_return': "è¾¾åˆ°-5%åˆ°+5%åŒºé—´",
        'win_rate': "30-40%",
        'sharpe_ratio': "0.5-1.0",
        'system_reliability': "å»ºç«‹å¯é çš„ç‰¹å¾å·¥ç¨‹æ–¹æ³•è®º"
    }
}
```

### ä¹è§‚é¢„æœŸ
```python
OPTIMISTIC_EXPECTATIONS = {
    'breakthrough_scenario': {
        'mean_return': "+10-15%",
        'win_rate': "55-65%",
        'sharpe_ratio': "1.5-2.0",
        'system_impact': "å»ºç«‹ä¸šç•Œé¢†å…ˆçš„RLäº¤æ˜“ç³»ç»Ÿ"
    }
}
```

### é•¿æœŸå½±å“
```python
LONG_TERM_IMPACT = {
    'methodology': "å»ºç«‹ç§‘å­¦çš„RLäº¤æ˜“ç‰¹å¾å·¥ç¨‹æ ‡å‡†",
    'academic_value': "ä¸ºå­¦æœ¯ç ”ç©¶æä¾›ä¸¥æ ¼çš„å®éªŒæ–¹æ³•è®º",
    'commercial_potential': "ä¸ºå•†ä¸šåŒ–äº¤æ˜“ç³»ç»Ÿå¥ å®šåŸºç¡€",
    'open_source_contribution': "ä¸ºå¼€æºç¤¾åŒºè´¡çŒ®æœ€ä½³å®è·µ"
}
```

---

## å®æ–½è®¡åˆ’

### ç¬¬1å‘¨ï¼šåŸºç¡€é˜¶æ®µ
```
Day 1-2: å¥–åŠ±å‡½æ•°é‡æ„å’Œæµ‹è¯•
Day 3-4: Phase 1åŸºå‡†å®éªŒæ‰§è¡Œ
Day 5-6: Phase 1ç»“æœåˆ†æå’ŒéªŒè¯
Day 7: Phase 1æŠ¥å‘Šå’ŒPhase 2å‡†å¤‡
```

### ç¬¬2å‘¨ï¼šç‰¹å¾æ‰©å±•
```
Day 8-10: Phase 2åŠ¨é‡ç‰¹å¾å®éªŒ
Day 11-12: Phase 3æ³¢åŠ¨ç‡ç‰¹å¾å®éªŒ
Day 13-14: ä¸­æœŸç»“æœåˆ†æå’Œè°ƒæ•´
```

### ç¬¬3å‘¨ï¼šä¼˜åŒ–å®Œå–„
```
Day 15-17: Phase 4è¶‹åŠ¿ç‰¹å¾å®éªŒ
Day 18-19: ç‰¹å¾é‡è¦æ€§åˆ†æå’Œå‰ªæ
Day 20-21: æœ€ç»ˆä¼˜åŒ–å’Œå®Œæ•´éªŒè¯
```

---

## æˆåŠŸå®šä¹‰

### æœ€å°æˆåŠŸæ ‡å‡† (Must Have)
1. âœ… è§£å†³å¥–åŠ±å‡½æ•°ä¸ä¸€è‡´é—®é¢˜ (ç›¸å…³ç³»æ•° > 0.8)
2. âœ… å®ç°æ˜¾è‘—æ€§èƒ½æ”¹å–„ (å›æŠ¥ç‡æ”¹å–„ > 20ä¸ªç™¾åˆ†ç‚¹)
3. âœ… å»ºç«‹ç§‘å­¦ç‰¹å¾é€‰æ‹©æ–¹æ³•è®º
4. âœ… è¯æ˜æ¸è¿›å¼æ–¹æ³•çš„æœ‰æ•ˆæ€§

### ç†æƒ³æˆåŠŸæ ‡å‡† (Should Have)
1. ğŸ¯ è¾¾åˆ°ç›ˆåˆ©æ°´å¹³ (å¹³å‡å›æŠ¥ > 0%)
2. ğŸ¯ å»ºç«‹è¡Œä¸šæ ‡å‡†æ–¹æ³•è®º
3. ğŸ¯ è·å¾—ç»Ÿè®¡æ˜¾è‘—çš„æ€§èƒ½æå‡
4. ğŸ¯ ä¸ºæœªæ¥ç ”ç©¶å¥ å®šåŸºç¡€

### çªç ´æ€§æˆåŠŸæ ‡å‡† (Could Have)
1. ğŸš€ å®ç°ç¨³å®šç›ˆåˆ© (å›æŠ¥ > 10%, Sharpe > 1.5)
2. ğŸš€ å»ºç«‹ä¸šç•Œé¢†å…ˆçš„RLäº¤æ˜“ç³»ç»Ÿ
3. ğŸš€ è·å¾—å­¦æœ¯å’Œå•†ä¸šä»·å€¼è®¤å¯
4. ğŸš€ å¼€åˆ›æ–°çš„ç ”ç©¶æ–¹å‘

---

## æ€»ç»“

Experiment #005ä»£è¡¨äº†ä»Experiment #004å¤±è´¥ä¸­å­¦ä¹ çš„ç§‘å­¦æ€åº¦å’Œä¸¥æ ¼æ–¹æ³•è®ºçš„ä½“ç°ã€‚é€šè¿‡ï¼š

1. **ç³»ç»Ÿæ€§é—®é¢˜è§£å†³** - é’ˆå¯¹#004çš„æ¯ä¸ªå…·ä½“é—®é¢˜è®¾è®¡è§£å†³æ–¹æ¡ˆ
2. **ç§‘å­¦å®éªŒæ–¹æ³•** - é‡‡ç”¨æ¸è¿›å¼ã€æ§åˆ¶å˜é‡ã€ç»Ÿè®¡æ£€éªŒçš„ä¸¥æ ¼æ–¹æ³•
3. **è´¨é‡ä¿è¯æœºåˆ¶** - å¤šé‡éªŒè¯ã€å¼‚å¸¸æ£€æµ‹ã€é£é™©ç¼“è§£
4. **æ˜ç¡®æˆåŠŸæ ‡å‡†** - å¯é‡åŒ–çš„ç›®æ ‡å’Œè¯„ä¼°ä½“ç³»

æˆ‘ä»¬æœŸå¾…Experiment #005ä¸ä»…è§£å†³å½“å‰çš„æŠ€æœ¯é—®é¢˜ï¼Œæ›´é‡è¦çš„æ˜¯å»ºç«‹ä¸€å¥—ç§‘å­¦ã€å¯å¤ç°ã€å¯æ‰©å±•çš„RLäº¤æ˜“ç³»ç»Ÿç‰¹å¾å·¥ç¨‹æ–¹æ³•è®ºï¼Œä¸ºæ•´ä¸ªé¢†åŸŸè´¡çŒ®ä»·å€¼ã€‚

**"Science advances through systematic experimentation and learning from failures"**

---

## ğŸ”´ PHASE 1 å®é™…æ‰§è¡Œç»“æœ (2025-08-12)

### ğŸ“Š æ‰§è¡Œé…ç½®
```python
ACTUAL_EXECUTION_CONFIG = {
    'training_framework': 'Stable-Baselines3 PPO',
    'total_timesteps': 3_000_000,  # 3Mæ­¥ (è¶…å‡ºè®¡åˆ’çš„1Mæ­¥)
    'training_time': 5_273,        # 5,273ç§’ (1.5å°æ—¶)
    'currency_pair': 'EURUSD',
    'feature_stage': 'stage2_10features',
    'reward_function': 'progressive_features',
    'algorithm': 'PPO (Proximal Policy Optimization)'
}
```

### ğŸ“ˆ è®­ç»ƒç»“æœ
```python
PHASE1_ACTUAL_RESULTS = {
    'performance_metrics': {
        'mean_reward': +1152.41,        # âœ… é«˜æ­£å€¼
        'std_reward': 0.30,             # âœ… ä½æ–¹å·®ï¼Œè®­ç»ƒç¨³å®š
        'mean_return': -63.76,          # âŒ ä¸¥é‡äºæŸ
        'std_return': 0.0,              # âŒ æ‰€æœ‰å›åˆéƒ½äºæŸ
        'win_rate': 0.0,                # âŒ æ— ç›ˆåˆ©å›åˆ
        'sharpe_ratio': -6375.56        # âŒ æå·®é£é™©è°ƒæ•´å›æŠ¥
    },
    'training_metrics': {
        'episode_length': 250_671,      # å¹³å‡æ­¥æ•°
        'convergence': 'stable',        # âœ… è®­ç»ƒè¿‡ç¨‹ç¨³å®š
        'total_episodes': 10            # è¯„ä¼°å›åˆæ•°
    }
}
```

### ğŸš¨ å…³é”®é—®é¢˜å‘ç°

#### 1. å¥–åŠ±-å›æŠ¥ä¸¥é‡è„±é’© âš ï¸
```python
CRITICAL_ISSUE = {
    'problem_type': 'å¥–åŠ±å‡½æ•°ä¸å®é™…äº¤æ˜“è¡¨ç°å®Œå…¨è„±é’©',
    'severity': 'CRITICAL - ç³»ç»Ÿæ€§å¤±è´¥',
    'evidence': {
        'reward_signal': +1152.41,     # æ¨¡å‹è®¤ä¸ºè¡¨ç°ä¼˜å¼‚
        'actual_performance': -63.76,   # å®é™…å·¨å¤§äºæŸ
        'correlation': 'æ¥è¿‘0',         # å®Œå…¨ä¸ç›¸å…³
        'consistency': 'å®Œå…¨å¤±è´¥'
    },
    'impact': 'è®­ç»ƒå‡ºçš„æ¨¡å‹å®Œå…¨è¯¯å¯¼ï¼Œæ— å•†ä¸šä»·å€¼'
}
```

#### 2. ç³»ç»Ÿæ€§äº¤æ˜“å¤±è´¥ ğŸ’¸
```python
TRADING_FAILURE_ANALYSIS = {
    'portfolio_trajectory': {
        'starting_balance': 10000.00,
        'ending_balance': 3624.44,
        'total_loss': 6375.56,
        'loss_percentage': 63.76
    },
    'pattern_analysis': {
        'win_rate': 0,
        'consecutive_losses': 10,  # æ‰€æœ‰å›åˆéƒ½äºæŸ
        'risk_management': 'å®Œå…¨å¤±æ•ˆ',
        'position_sizing': 'å¯èƒ½å­˜åœ¨è¿‡åº¦äº¤æ˜“'
    }
}
```

#### 3. å¥–åŠ±å‡½æ•°è®¾è®¡ç¼ºé™· ğŸ”§
```python
REWARD_FUNCTION_DIAGNOSIS = {
    'current_function': 'progressive_features',
    'suspected_issues': [
        'å¥–åŠ±è®¡ç®—ä¸å®é™…ç›ˆäºè„±èŠ‚',
        'å¯èƒ½å­˜åœ¨æ•°å€¼ç¨³å®šæ€§é—®é¢˜', 
        'å¥–åŠ±ä¿¡å·æ–¹å‘æ€§é”™è¯¯',
        'ç¼ºä¹å®é™…äº¤æ˜“æˆæœ¬è€ƒè™‘'
    ],
    'recommended_fix': 'ç«‹å³åˆ‡æ¢åˆ°simple_returnæˆ–ç›´æ¥ç›ˆäºå¥–åŠ±'
}
```

### ğŸ“‹ Phase 1 æˆåŠŸæ ‡å‡†å¯¹æ¯”
```python
PHASE1_SUCCESS_VS_ACTUAL = {
    'target_vs_actual': {
        'mean_return': {
            'target': '> -20%',
            'actual': '-63.76%',
            'status': 'âŒ å¤§å¹…æœªè¾¾æ ‡ (-43.76ä¸ªç™¾åˆ†ç‚¹)'
        },
        'reward_return_correlation': {
            'target': '> 0.8',
            'actual': 'æ¥è¿‘0',
            'status': 'âŒ å®Œå…¨å¤±è´¥'
        },
        'win_rate': {
            'target': '> 20%',
            'actual': '0%',
            'status': 'âŒ å®Œå…¨å¤±è´¥'
        },
        'training_stability': {
            'target': 'æŸå¤±æ”¶æ•›ä¸”ç¨³å®š',
            'actual': 'è®­ç»ƒè¿‡ç¨‹ç¨³å®š',
            'status': 'âœ… è¾¾æ ‡'
        }
    },
    'overall_assessment': 'PHASE 1 ä¸¥é‡å¤±è´¥ï¼Œéœ€è¦æ ¹æœ¬æ€§é‡æ–°è®¾è®¡'
}
```

### ğŸ” æ ¹å› åˆ†æ

#### ä¸»è¦é—®é¢˜æ ¹æº
```python
ROOT_CAUSE_ANALYSIS = {
    'primary_cause': 'å¥–åŠ±å‡½æ•°è®¾è®¡æ ¹æœ¬æ€§ç¼ºé™·',
    'contributing_factors': [
        'å¥–åŠ±å‡½æ•°progressive_featureså¯èƒ½æœ‰bugæˆ–è®¾è®¡é”™è¯¯',
        'ç‰¹å¾é€‰æ‹©é˜¶æ®µ2_10featureså¯èƒ½ä¸è¶³æˆ–æœ‰è¯¯',
        'ç¼ºä¹é€‚å½“çš„é£é™©ç®¡ç†æœºåˆ¶',
        'äº¤æ˜“æˆæœ¬è®¡ç®—å¯èƒ½ä¸å‡†ç¡®'
    ],
    'system_level_issues': [
        'å¥–åŠ±å‡½æ•°éªŒè¯æœºåˆ¶ä¸è¶³',
        'ç¼ºä¹å®æ—¶å¥–åŠ±-å›æŠ¥ä¸€è‡´æ€§ç›‘æ§',
        'æ²¡æœ‰å¼‚å¸¸å¥–åŠ±å€¼çš„é¢„è­¦ç³»ç»Ÿ'
    ]
}
```

#### æŠ€æœ¯è¯Šæ–­
```python
TECHNICAL_DIAGNOSIS = {
    'reward_function_bug': {
        'evidence': 'é«˜å¥–åŠ±å€¼ (+1152) vs å®é™…äºæŸ (-63%)',
        'hypothesis': 'progressive_featureså¥–åŠ±è®¡ç®—é€»è¾‘é”™è¯¯',
        'verification_needed': 'æ£€æŸ¥å¥–åŠ±å‡½æ•°æºä»£ç '
    },
    'feature_quality': {
        'evidence': 'è®­ç»ƒç¨³å®šä½†ç»“æœå·®',
        'hypothesis': '10ä¸ªç‰¹å¾è´¨é‡ä¸è¶³æˆ–ç›¸å…³æ€§å·®',
        'verification_needed': 'ç‰¹å¾é‡è¦æ€§åˆ†æ'
    },
    'training_config': {
        'evidence': '3Mæ­¥è®­ç»ƒä½†ä»ç„¶å¤±è´¥',
        'hypothesis': 'è¶…å‚æ•°é…ç½®ä¸å½“',
        'verification_needed': 'è¶…å‚æ•°æ•æ„Ÿæ€§åˆ†æ'
    }
}
```

### ğŸ› ï¸ ç´§æ€¥ä¿®å¤è®¡åˆ’

#### ç«‹å³è¡ŒåŠ¨ (ä¼˜å…ˆçº§1)
```python
IMMEDIATE_ACTIONS = {
    '1_reward_function_fix': {
        'action': 'ç«‹å³åˆ‡æ¢åˆ°simple_returnå¥–åŠ±å‡½æ•°',
        'rationale': 'ç¡®ä¿å¥–åŠ±ä¸å®é™…ç›ˆäºä¸€è‡´',
        'timeline': 'ç«‹å³æ‰§è¡Œ',
        'verification': 'å°è§„æ¨¡éªŒè¯å®éªŒ (50ä¸‡æ­¥)'
    },
    '2_feature_validation': {
        'action': 'å‡å°‘ç‰¹å¾åˆ°æœ€åŸºæœ¬çš„3ä¸ª (Close, Volume, Returns)',
        'rationale': 'æ’é™¤ç‰¹å¾å¤æ‚æ€§å½±å“',
        'timeline': 'ç«‹å³æ‰§è¡Œ',
        'verification': 'å¯¹æ¯”å®éªŒ'
    },
    '3_sanity_check': {
        'action': 'è¿è¡Œæœ€ç®€å•é…ç½®éªŒè¯ç³»ç»Ÿæ­£å¸¸æ€§',
        'rationale': 'ç¡®è®¤ç³»ç»ŸåŸºç¡€åŠŸèƒ½æ­£å¸¸',
        'timeline': '24å°æ—¶å†…',
        'success_criteria': 'å¥–åŠ±ä¸å›æŠ¥ç›¸å…³æ€§ > 0.5'
    }
}
```

#### çŸ­æœŸä¿®å¤ (ä¼˜å…ˆçº§2)
```python
SHORT_TERM_FIXES = {
    'code_audit': {
        'action': 'å®¡æŸ¥progressive_featureså¥–åŠ±å‡½æ•°ä»£ç ',
        'timeline': '2-3å¤©',
        'deliverable': 'è¯¦ç»†bugæŠ¥å‘Š'
    },
    'baseline_reestablish': {
        'action': 'é‡æ–°å»ºç«‹å¯é çš„åŸºå‡†æ€§èƒ½',
        'timeline': '1å‘¨',
        'target': 'å¥–åŠ±-å›æŠ¥ç›¸å…³æ€§ > 0.8'
    },
    'monitoring_enhancement': {
        'action': 'åŠ å¼ºè®­ç»ƒè¿‡ç¨‹å®æ—¶ç›‘æ§',
        'timeline': '1å‘¨',
        'deliverable': 'å¼‚å¸¸æ£€æµ‹ç³»ç»Ÿ'
    }
}
```

### ğŸ“Š å®éªŒ5 Phase 1 ç»“è®º

#### æ ¸å¿ƒå‘ç°
1. **ğŸš¨ ç³»ç»Ÿæ€§å¤±è´¥**: å¥–åŠ±å‡½æ•°ä¸äº¤æ˜“è¡¨ç°å®Œå…¨è„±é’©ï¼Œå¯¼è‡´è®­ç»ƒæ— æ„ä¹‰
2. **âš ï¸ è®¾è®¡ç¼ºé™·**: progressive_featureså¥–åŠ±å‡½æ•°å­˜åœ¨æ ¹æœ¬æ€§é—®é¢˜
3. **âœ… è®­ç»ƒç¨³å®š**: è®­ç»ƒè¿‡ç¨‹æŠ€æœ¯å±‚é¢ç¨³å®šï¼Œé—®é¢˜åœ¨äºç›®æ ‡å‡½æ•°
4. **ğŸ”„ éœ€è¦é‡å¯**: å¿…é¡»å›åˆ°æœ€åŸºç¡€é…ç½®é‡æ–°éªŒè¯ç³»ç»Ÿ

#### å­¦ä¹ æˆæœ
1. **éªŒè¯äº†æ—¥å¿—ç³»ç»Ÿä¿®å¤**: è®­ç»ƒæ—¥å¿—å®Œæ•´è®°å½•ï¼Œä¾¿äºé—®é¢˜åˆ†æ
2. **å‘ç°äº†å…³é”®ç³»ç»Ÿæ€§é—®é¢˜**: é¿å…äº†æ›´å¤§è§„æ¨¡çš„æ— æ•ˆè®­ç»ƒ
3. **å»ºç«‹äº†ä¸¥æ ¼çš„é—®é¢˜è¯Šæ–­æµç¨‹**: ä¸ºåç»­å®éªŒå¥ å®šåŸºç¡€
4. **æ˜ç¡®äº†ä¼˜å…ˆçº§**: å¥–åŠ±å‡½æ•°ä¸€è‡´æ€§æ˜¯ç¬¬ä¸€è¦åŠ¡

#### ä¸‹ä¸€æ­¥è¡ŒåŠ¨
```python
NEXT_STEPS = {
    'experiment_5_phase_2': 'æš‚åœï¼Œç­‰å¾…Phase 1é—®é¢˜ä¿®å¤',
    'emergency_experiment_6': {
        'name': 'å¥–åŠ±å‡½æ•°ä¿®å¤éªŒè¯å®éªŒ',
        'objective': 'éªŒè¯simple_returnå¥–åŠ±å‡½æ•°çš„ä¸€è‡´æ€§',
        'timeline': 'ç«‹å³å¼€å§‹',
        'duration': '2-3å°æ—¶å¿«é€ŸéªŒè¯'
    },
    'system_refactoring': 'è€ƒè™‘å¥–åŠ±å‡½æ•°æ¶æ„é‡æ„',
    'methodology_review': 'å®¡æŸ¥å®éªŒæ–¹æ³•è®ºå’Œè´¨é‡æ§åˆ¶æœºåˆ¶'
}
```

---

*å®éªŒè®¾è®¡è´Ÿè´£äºº: TensorTradeç ”ç©¶å›¢é˜Ÿ*  
*è®¾è®¡å®Œæˆæ—¶é—´: 2025å¹´8æœˆ12æ—¥*  
*Phase 1æ‰§è¡Œæ—¶é—´: 2025å¹´8æœˆ12æ—¥ 16:42-18:52*  
*å®éªŒçŠ¶æ€: ğŸ”´ Phase 1å¤±è´¥ï¼Œç´§æ€¥ä¿®å¤ä¸­*