"""
Experiment #005: ä¼˜åŒ–çš„å¤–æ±‡å¥–åŠ±å‡½æ•° - é›†æˆç‰ˆæœ¬
è§£å†³Experiment #004ä¸­å¥–åŠ±å€¼ä¸å›æŠ¥ç‡ä¸ä¸€è‡´çš„é—®é¢˜ï¼Œé›†æˆåˆ°é¡¹ç›®æ¡†æ¶ä¸­
"""

import numpy as np
import logging
from typing import Dict, Any, Optional, List
from collections import deque
from dataclasses import dataclass
from .base_reward import BaseRewardScheme

@dataclass
class OptimizedForexRewardConfig:
    """ä¼˜åŒ–å¤–æ±‡å¥–åŠ±å‡½æ•°é…ç½®"""
    return_weight: float = 1.0
    risk_penalty: float = 0.1
    transaction_cost: float = 0.0001
    consistency_bonus: float = 0.05
    volatility_adjustment: bool = True
    clip_range: tuple = (-1.0, 1.0)
    stability_window: int = 20
    correlation_threshold: float = 0.8
    pip_size: float = 0.0001
    daily_target_pips: float = 20.0
    
class OptimizedForexReward(BaseRewardScheme):
    """
    Experiment #005: é’ˆå¯¹å¤–æ±‡å¸‚åœºä¼˜åŒ–çš„å¥–åŠ±å‡½æ•°
    
    å…³é”®æ”¹è¿›ï¼ˆè§£å†³Experiment #004é—®é¢˜ï¼‰ï¼š
    1. ç›´æ¥åŸºäºå®é™…æŠ•èµ„ç»„åˆå›æŠ¥è®¡ç®—å¥–åŠ±ï¼Œç¡®ä¿é«˜ç›¸å…³æ€§
    2. æ•°å€¼ç¨³å®šæ€§æ§åˆ¶ï¼Œé¿å…å¼‚å¸¸å¤§çš„å¥–åŠ±å€¼ï¼ˆå¦‚+94542ï¼‰
    3. å®æ—¶ç›¸å…³æ€§ç›‘æ§å’ŒéªŒè¯
    4. å¤–æ±‡å¸‚åœºç‰¹å¾ä¼˜åŒ–ï¼ˆç‚¹æ•°ã€è¶‹åŠ¿ã€è´¨é‡ã€é£é™©ï¼‰
    5. è‡ªé€‚åº”å¥–åŠ±èŒƒå›´é™åˆ¶
    """
    
    def __init__(self, 
                 initial_balance: float = 10000.0,
                 config: Optional[OptimizedForexRewardConfig] = None,
                 base_currency_pair: str = "EURUSD",
                 **kwargs):
        """
        åˆå§‹åŒ–ä¼˜åŒ–å¤–æ±‡å¥–åŠ±å‡½æ•°
        
        Args:
            initial_balance: åˆå§‹èµ„é‡‘
            config: ä¼˜åŒ–é…ç½®
            base_currency_pair: åŸºç¡€è´§å¸å¯¹
        """
        super().__init__(initial_balance=initial_balance, **kwargs)
        
        # é…ç½®åˆå§‹åŒ–
        self.config = config or OptimizedForexRewardConfig()
        self.currency_pair = base_currency_pair
        
        # Experiment #005: å¥–åŠ±-å›æŠ¥ä¸€è‡´æ€§è¿½è¸ª
        self.returns_history = []
        self.rewards_history = []
        self.portfolio_values = []
        self.prev_portfolio_value = None
        self.prev_action = 0.0
        self.step_count = 0
        
        # ç»Ÿè®¡æŒ‡æ ‡
        self.correlation_score = 0.0
        self.consistency_score = 0.0
        
        # è­¦å‘ŠèŠ‚æµæœºåˆ¶
        self.last_correlation_warning = 0
        self.last_abnormal_reward_warning = 0
        self.correlation_warning_interval = 100  # æ¯100æ­¥æœ€å¤šè­¦å‘Šä¸€æ¬¡
        self.abnormal_reward_warning_interval = 50  # å¼‚å¸¸å¥–åŠ±è­¦å‘Šé—´éš”
        
        # å¤–æ±‡ä¸“ç”¨å†å²æ•°æ®
        self.price_history = deque(maxlen=50)
        self.action_history = deque(maxlen=20)
        self.pip_profits = deque(maxlen=100)
        self.volatility_history = deque(maxlen=30)
        
        # æ€§èƒ½æŒ‡æ ‡
        self.consecutive_wins = 0
        self.consecutive_losses = 0
        self.daily_pip_count = 0
        
        # å¥–åŠ±æƒé‡é…ç½® (é™ä½æƒé‡ï¼Œä»¥å®é™…å›æŠ¥ä¸ºä¸»)
        self.weights = {
            'pip_reward': 0.15,      # é™ä½ç‚¹æ•°æƒé‡
            'trend_reward': 0.10,    # é™ä½è¶‹åŠ¿æƒé‡
            'quality_reward': 0.10,  # é™ä½è´¨é‡æƒé‡  
            'risk_reward': 0.05      # é™ä½é£é™©æƒé‡
        }
        
        self.logger = logging.getLogger(f"OptimizedForexReward_{self.currency_pair}")
        self.logger.info("åˆå§‹åŒ–Experiment #005ä¼˜åŒ–å¤–æ±‡å¥–åŠ±å‡½æ•°")
        
    def calculate_reward(self, observation: Dict = None, action: float = 0.0, 
                        next_observation: Dict = None, info: Dict = None,
                        # å‘åå…¼å®¹å‚æ•°
                        portfolio_value: float = None, price: float = None,
                        portfolio_info: Dict = None, trade_info: Dict = None, 
                        step: int = 0, **kwargs) -> float:
        """
        è®¡ç®—ä¼˜åŒ–çš„å¤–æ±‡å¥–åŠ± - è§£å†³Experiment #004é—®é¢˜
        
        æ ¸å¿ƒæ”¹è¿›ï¼šç›´æ¥åŸºäºå®é™…æŠ•èµ„ç»„åˆå›æŠ¥è®¡ç®—ï¼Œç¡®ä¿å¥–åŠ±-å›æŠ¥é«˜ç›¸å…³æ€§
        """
        try:
            # å…¼å®¹æ–°æ—§APIè°ƒç”¨æ–¹å¼
            current_portfolio = self._get_portfolio_value(portfolio_value, info)
            current_price = self._get_price(price, observation)
            
            # é¦–æ¬¡è°ƒç”¨åˆå§‹åŒ–
            if self.prev_portfolio_value is None:
                self.prev_portfolio_value = current_portfolio
                return 0.0
            
            # 1. è®¡ç®—å®é™…å›æŠ¥ç‡ - æ ¸å¿ƒæ”¹è¿›
            actual_return = self._calculate_return(self.prev_portfolio_value, current_portfolio)
            
            # 2. è®¡ç®—äº¤æ˜“æˆæœ¬
            transaction_cost = self._calculate_transaction_cost(action)
            
            # 3. è®¡ç®—é£é™©æƒ©ç½š
            risk_penalty = self._calculate_risk_penalty(observation, action)
            
            # 4. åŸºç¡€å¥–åŠ± = å®é™…å›æŠ¥ç‡
            base_reward = actual_return * self.config.return_weight
            
            # 5. å¤–æ±‡ç‰¹å¾åŠ æˆï¼ˆå¯é€‰ï¼Œæƒé‡è¾ƒä½ï¼‰
            forex_bonus = 0.0
            if current_price is not None:
                forex_bonus = self._calculate_forex_bonus(current_price, action)
            
            # 6. æœ€ç»ˆå¥–åŠ±è®¡ç®—
            final_reward = base_reward - transaction_cost - risk_penalty + forex_bonus
            
            # 7. æ•°å€¼ç¨³å®šæ€§æ§åˆ¶ - è§£å†³#004å¼‚å¸¸å¥–åŠ±å€¼é—®é¢˜
            stable_reward = self._apply_stability_controls(final_reward)
            
            # 8. æ›´æ–°è¿½è¸ªå†å²
            self._update_tracking_history(actual_return, stable_reward, current_portfolio)
            
            # 9. æ›´æ–°çŠ¶æ€
            self.prev_portfolio_value = current_portfolio
            self.prev_action = action
            self.step_count += 1
            
            return stable_reward
            
        except Exception as e:
            self.logger.error(f"å¥–åŠ±è®¡ç®—é”™è¯¯: {e}")
            return 0.0
    
    def _get_portfolio_value(self, portfolio_value: float, info: Dict) -> float:
        """è·å–æŠ•èµ„ç»„åˆä»·å€¼"""
        if portfolio_value is not None:
            return portfolio_value
        if info is not None:
            return info.get('portfolio_value', self.initial_balance)
        return self.initial_balance
    
    def _get_price(self, price: float, observation: Dict) -> Optional[float]:
        """è·å–å½“å‰ä»·æ ¼"""
        if price is not None:
            return price
        if observation is not None:
            return observation.get('close', observation.get('price'))
        return None
    
    def _calculate_return(self, prev_value: float, current_value: float) -> float:
        """è®¡ç®—å®é™…å›æŠ¥ç‡"""
        if prev_value <= 0:
            return 0.0
        return (current_value - prev_value) / prev_value
    
    def _calculate_transaction_cost(self, action: float) -> float:
        """è®¡ç®—äº¤æ˜“æˆæœ¬"""
        position_change = abs(action - self.prev_action)
        return position_change * self.config.transaction_cost
    
    def _calculate_risk_penalty(self, observation: Dict, action: float) -> float:
        """è®¡ç®—é£é™©æƒ©ç½š"""
        if not self.config.volatility_adjustment:
            return 0.0
        
        # ä¼°ç®—å½“å‰æ³¢åŠ¨ç‡
        volatility = self._estimate_volatility(observation)
        
        # é£é™©æƒ©ç½š = æ³¢åŠ¨ç‡ Ã— ä»“ä½å¤§å° Ã— æƒ©ç½šç³»æ•°
        risk_penalty = volatility * abs(action) * self.config.risk_penalty
        
        return risk_penalty
    
    def _estimate_volatility(self, observation: Dict) -> float:
        """ä¼°ç®—å½“å‰æ³¢åŠ¨ç‡"""
        try:
            if observation is None:
                return 0.01
            
            # å°è¯•ä»è§‚å¯Ÿä¸­è·å–ATRæˆ–å…¶ä»–æ³¢åŠ¨ç‡æŒ‡æ ‡
            if 'ATR_14' in observation:
                atr = observation['ATR_14']
                price = observation.get('close', observation.get('price', 1.0))
                return atr / price if price > 0 else 0.01
            
            # å¦‚æœæ²¡æœ‰ATRï¼Œä½¿ç”¨å†å²å›æŠ¥ç‡ä¼°ç®—
            if len(self.returns_history) >= 5:
                recent_returns = self.returns_history[-5:]
                return np.std(recent_returns) if len(recent_returns) > 1 else 0.01
            
            return 0.01  # é»˜è®¤æ³¢åŠ¨ç‡
            
        except Exception as e:
            self.logger.warning(f"æ³¢åŠ¨ç‡ä¼°ç®—é”™è¯¯: {e}")
            return 0.01
    
    def _calculate_forex_bonus(self, current_price: float, action: float) -> float:
        """è®¡ç®—å¤–æ±‡ç‰¹å¾åŠ æˆï¼ˆæƒé‡è¾ƒä½ï¼‰"""
        try:
            self.price_history.append(current_price)
            self.action_history.append(action)
            
            if len(self.price_history) < 5:
                return 0.0
            
            # ç‚¹æ•°æ”¶ç›Š
            pip_reward = self._calculate_pip_reward(current_price, action)
            
            # è¶‹åŠ¿å¥–åŠ±
            trend_reward = self._calculate_trend_reward(current_price, action)
            
            # è´¨é‡å¥–åŠ±
            quality_reward = self._calculate_quality_reward(action)
            
            # ç»¼åˆå¤–æ±‡åŠ æˆï¼ˆæƒé‡å¾ˆä½ï¼Œä¸å½±å“ä¸»è¦çš„å›æŠ¥ç›¸å…³æ€§ï¼‰
            forex_bonus = (
                pip_reward * self.weights['pip_reward'] +
                trend_reward * self.weights['trend_reward'] +
                quality_reward * self.weights['quality_reward']
            )
            
            return forex_bonus * 0.1  # è¿›ä¸€æ­¥é™ä½æƒé‡
            
        except Exception as e:
            self.logger.warning(f"å¤–æ±‡åŠ æˆè®¡ç®—é”™è¯¯: {e}")
            return 0.0
    
    def _calculate_pip_reward(self, current_price: float, action: float) -> float:
        """è®¡ç®—ç‚¹æ•°æ”¶ç›Šå¥–åŠ±"""
        if len(self.price_history) < 2:
            return 0.0
        
        # è®¡ç®—ä»·æ ¼å˜åŒ– (pips)
        prev_price = self.price_history[-2]
        price_change = current_price - prev_price
        pip_change = price_change / self.config.pip_size
        
        # è®¡ç®—ç‚¹æ•°æ”¶ç›Š
        pip_profit = pip_change * action
        self.pip_profits.append(pip_profit)
        self.daily_pip_count += pip_profit
        
        # å¥–åŠ±è®¡ç®—
        base_pip_reward = pip_profit / self.config.daily_target_pips
        
        return base_pip_reward
    
    def _calculate_trend_reward(self, current_price: float, action: float) -> float:
        """è®¡ç®—è¶‹åŠ¿è·Ÿéšå¥–åŠ±"""
        if len(self.price_history) < 10:
            return 0.0
        
        # è®¡ç®—ç®€å•è¶‹åŠ¿
        recent_prices = list(self.price_history)[-10:]
        trend = recent_prices[-1] - recent_prices[0]
        
        # è¶‹åŠ¿æ–¹å‘ä¸åŠ¨ä½œä¸€è‡´æ€§
        trend_alignment = action * np.sign(trend)
        
        return trend_alignment * 0.5
    
    def _calculate_quality_reward(self, action: float) -> float:
        """è®¡ç®—äº¤æ˜“è´¨é‡å¥–åŠ±"""
        if len(self.action_history) < 3:
            return 0.0
        
        # åŠ¨ä½œç¨³å®šæ€§
        recent_actions = list(self.action_history)[-3:]
        action_changes = sum([abs(recent_actions[i] - recent_actions[i-1]) 
                            for i in range(1, len(recent_actions))])
        
        stability_score = max(0, 1.0 - action_changes / 2.0)
        
        return stability_score * 0.3
    
    def _apply_stability_controls(self, reward: float) -> float:
        """åº”ç”¨æ•°å€¼ç¨³å®šæ€§æ§åˆ¶ - è§£å†³#004å¼‚å¸¸å¥–åŠ±å€¼é—®é¢˜"""
        # 1. å¼‚å¸¸å€¼æ£€æµ‹å’Œä¿®æ­£
        if abs(reward) > 10:  # å¼‚å¸¸å¤§çš„å¥–åŠ±å€¼
            # é™é»˜ä¿®æ­£å¼‚å¸¸å¥–åŠ±å€¼ï¼Œä¸è¾“å‡ºè­¦å‘Š
            # if self.step_count - self.last_abnormal_reward_warning >= self.abnormal_reward_warning_interval:
            #     self.logger.warning(f"æ£€æµ‹åˆ°å¼‚å¸¸å¥–åŠ±å€¼: {reward}, è¿›è¡Œä¿®æ­£ (æ­¥æ•°: {self.step_count})")
            #     self.last_abnormal_reward_warning = self.step_count
            reward = np.sign(reward) * min(abs(reward), 1.0)
        
        # 2. èŒƒå›´é™åˆ¶
        reward = np.clip(reward, *self.config.clip_range)
        
        # 3. æ•°å€¼ç¨³å®šæ€§æ£€æŸ¥
        if not np.isfinite(reward):
            self.logger.error("å¥–åŠ±å€¼ä¸æ˜¯æœ‰é™æ•°å€¼ï¼Œè®¾ä¸º0")
            reward = 0.0
        
        return reward
    
    def _update_tracking_history(self, return_val: float, reward: float, 
                               portfolio_value: float):
        """æ›´æ–°è¿½è¸ªå†å²"""
        self.returns_history.append(return_val)
        self.rewards_history.append(reward)
        self.portfolio_values.append(portfolio_value)
        
        # ä¿æŒå†å²è®°å½•é•¿åº¦
        max_history = self.config.stability_window * 10
        if len(self.returns_history) > max_history:
            self.returns_history = self.returns_history[-max_history:]
            self.rewards_history = self.rewards_history[-max_history:]
            self.portfolio_values = self.portfolio_values[-max_history:]
        
        # å®šæœŸè®¡ç®—ç›¸å…³æ€§
        if len(self.returns_history) >= self.config.stability_window:
            self._update_correlation_score()
    
    def _update_correlation_score(self):
        """æ›´æ–°å¥–åŠ±-å›æŠ¥ç›¸å…³æ€§è¯„åˆ†"""
        try:
            if len(self.returns_history) < 10:
                return
            
            recent_returns = self.returns_history[-self.config.stability_window:]
            recent_rewards = self.rewards_history[-self.config.stability_window:]
            
            # è®¡ç®—ç›¸å…³ç³»æ•°
            correlation = np.corrcoef(recent_returns, recent_rewards)[0, 1]
            
            if np.isfinite(correlation):
                self.correlation_score = correlation
            
            # ç›¸å…³æ€§ç›‘æ§ï¼ˆä»…è®°å½•ï¼Œä¸è¾“å‡ºè­¦å‘Šï¼‰
            # æ³¨é‡Šæ‰è­¦å‘Šè¾“å‡ºï¼Œé¿å…æ—¥å¿—å¹²æ‰°
            # if abs(self.correlation_score) < self.config.correlation_threshold:
            #     # åªåœ¨é—´éš”æ—¶é—´åæ‰è¾“å‡ºè­¦å‘Š
            #     if self.step_count - self.last_correlation_warning >= self.correlation_warning_interval:
            #         self.logger.warning(
            #             f"å¥–åŠ±-å›æŠ¥ç›¸å…³æ€§è¾ƒä½: {self.correlation_score:.3f} (æ­¥æ•°: {self.step_count})"
            #         )
            #         self.last_correlation_warning = self.step_count
            
        except Exception as e:
            # é™é»˜å¤„ç†ç›¸å…³æ€§è®¡ç®—é”™è¯¯ï¼Œé¿å…æ—¥å¿—å¹²æ‰°
            # self.logger.warning(f"ç›¸å…³æ€§è®¡ç®—é”™è¯¯: {e}")
            pass
    
    def get_reward_info(self) -> Dict[str, Any]:
        """è·å–å¥–åŠ±å‡½æ•°ä¿¡æ¯"""
        return {
            "name": "OptimizedForexReward",
            "description": "Experiment #005ä¼˜åŒ–å¤–æ±‡å¥–åŠ±å‡½æ•°ï¼Œè§£å†³#004å¥–åŠ±-å›æŠ¥ä¸ä¸€è‡´é—®é¢˜",
            "category": "forex_optimized_enhanced",
            "experiment": "005",
            "key_improvements": [
                "ç›´æ¥åŸºäºå®é™…æŠ•èµ„ç»„åˆå›æŠ¥è®¡ç®—",
                "æ•°å€¼ç¨³å®šæ€§æ§åˆ¶ï¼Œé¿å…å¼‚å¸¸å¥–åŠ±å€¼",
                "å®æ—¶å¥–åŠ±-å›æŠ¥ç›¸å…³æ€§ç›‘æ§",
                "è‡ªé€‚åº”å¥–åŠ±èŒƒå›´é™åˆ¶",
                "å¤–æ±‡å¸‚åœºç‰¹å¾ä¼˜åŒ–"
            ],
            "parameters": {
                "return_weight": self.config.return_weight,
                "risk_penalty": self.config.risk_penalty,
                "transaction_cost": self.config.transaction_cost,
                "clip_range": self.config.clip_range,
                "correlation_threshold": self.config.correlation_threshold
            },
            "current_stats": {
                "correlation_score": self.correlation_score,
                "steps_processed": self.step_count,
                "history_length": len(self.returns_history)
            },
            "suitable_for": ["EURUSD", "GBPUSD", "USDJPY", "å¤–æ±‡ä¸»è¦è´§å¸å¯¹"],
            "expected_reward_range": self.config.clip_range
        }
    
    def reset(self):
        """é‡ç½®å¥–åŠ±å‡½æ•°çŠ¶æ€"""
        super().reset()
        self.prev_portfolio_value = None
        self.prev_action = 0.0
        self.step_count = 0
        
        # ä¿ç•™éƒ¨åˆ†å†å²ç”¨äºè¿ç»­å­¦ä¹ 
        self.returns_history = []
        self.rewards_history = []
        self.portfolio_values = []
        
        # æ¸…ç©ºå¤–æ±‡ä¸“ç”¨å†å²
        self.price_history.clear()
        self.action_history.clear()
        self.pip_profits.clear()
        self.volatility_history.clear()
        
        self.consecutive_wins = 0
        self.consecutive_losses = 0
        self.daily_pip_count = 0
    
    def validate_reward_return_consistency(self, min_correlation: float = None) -> bool:
        """éªŒè¯å¥–åŠ±ä¸å›æŠ¥çš„ä¸€è‡´æ€§"""
        threshold = min_correlation or self.config.correlation_threshold
        
        if len(self.returns_history) < 20:
            return False
        
        return abs(self.correlation_score) >= threshold
    
    def get_diagnostics(self) -> Dict[str, Any]:
        """è·å–è¯Šæ–­ä¿¡æ¯"""
        if len(self.returns_history) < 2:
            return {"status": "insufficient_data"}
        
        return {
            "experiment": "005",
            "correlation_score": self.correlation_score,
            "mean_return": np.mean(self.returns_history),
            "mean_reward": np.mean(self.rewards_history),
            "return_volatility": np.std(self.returns_history),
            "reward_volatility": np.std(self.rewards_history),
            "consistency_check": self.validate_reward_return_consistency(),
            "total_steps": self.step_count,
            "current_portfolio": self.portfolio_values[-1] if self.portfolio_values else None,
            "reward_range": [min(self.rewards_history), max(self.rewards_history)] if self.rewards_history else [0, 0],
            "improvement_vs_004": "è§£å†³å¥–åŠ±-å›æŠ¥ä¸ä¸€è‡´é—®é¢˜ï¼Œæ•°å€¼ç¨³å®šæ€§æ§åˆ¶"
        }

# å·¥å‚å‡½æ•°
def create_optimized_forex_reward(config: Dict[str, Any] = None) -> OptimizedForexReward:
    """åˆ›å»ºä¼˜åŒ–å¤–æ±‡å¥–åŠ±å‡½æ•°çš„å·¥å‚æ–¹æ³•"""
    if config is None:
        config = {}
    
    # æå–OptimizedForexRewardConfigå‚æ•°
    reward_config_params = {}
    for key in OptimizedForexRewardConfig.__dataclass_fields__.keys():
        if key in config:
            reward_config_params[key] = config.pop(key)
    
    reward_config = OptimizedForexRewardConfig(**reward_config_params)
    return OptimizedForexReward(config=reward_config, **config)

if __name__ == "__main__":
    # æµ‹è¯•ä¼˜åŒ–å¤–æ±‡å¥–åŠ±å‡½æ•°
    print("ğŸ§ª æµ‹è¯•OptimizedForexReward (Experiment #005)...")
    
    # åˆ›å»ºå¥–åŠ±å‡½æ•°
    reward_fn = create_optimized_forex_reward({
        'return_weight': 1.0,
        'risk_penalty': 0.1,
        'transaction_cost': 0.0001,
        'initial_balance': 10000.0
    })
    
    # æ¨¡æ‹Ÿæµ‹è¯•æ•°æ®
    test_observation = {
        'close': 1.1000,
        'ATR_14': 0.0012,
        'RSI_14': 50.0
    }
    
    test_info = {'portfolio_value': 10000.0}
    
    # æµ‹è¯•å¥–åŠ±è®¡ç®—
    reward = reward_fn.calculate_reward(
        observation=test_observation,
        action=0.5,
        next_observation=test_observation,
        info=test_info
    )
    
    print(f"âœ… æµ‹è¯•å¥–åŠ±å€¼: {reward}")
    
    # æ˜¾ç¤ºå¥–åŠ±å‡½æ•°ä¿¡æ¯
    info = reward_fn.get_reward_info()
    print(f"âœ… å¥–åŠ±å‡½æ•°ä¿¡æ¯:")
    print(f"   åç§°: {info['name']}")
    print(f"   å®éªŒ: {info['experiment']}")
    print(f"   æè¿°: {info['description']}")
    print(f"   å…³é”®æ”¹è¿›: {info['key_improvements']}")
    
    print("\nğŸ¯ OptimizedForexReward (Experiment #005) å‡†å¤‡å°±ç»ª!")